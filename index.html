<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>

<title>Eshed Ohn-Bar</title>
<link href='//fonts.googleapis.com/css?family=Lato:300,400,700' rel='stylesheet' type='text/css'>

<!--
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-40627132-1', 'ucsd.edu');
  ga('send', 'pageview');

</script>
!-->

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-40627132-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-40627132-1');
</script>


<script src="courses/jquery-1.js"></script>
  <link rel="stylesheet" href="bootstrap.css">
  <link rel="stylesheet" href="bootstrap-theme.css">
  <script src="courses/bootstrap.js"></script>

  <style>
     .panel-heading .accordion-toggle:before {
      font-family: 'Glyphicons Halflings';
      content: "\e114";
      float: left;
      color: grey;
      padding-right: 6px;
    }
    .panel-heading .accordion-toggle.collapsed:before {
      content: "\e080";
    }
table, th, td {
    border: 0px solid black;
    border-collapse: collapse;
}
img:hover{
  transition-duration: 0.0s;
  transition-timing-function: linear;
opacity:0.5;
}
  </style>

<style type="text/css">
</style>

<style>
@media screen and (max-device-width: 480px){
  body{
      -webkit-text-size-adjust: 100%;
        }
        }
p { font-size : 17px; }
h1 { padding : 0; margin : 0; font-size : 36px; }
h2 { font-size : 22px; margin : 0; padding : 0; }
body { padding : 0; font-family: 'Lato', sans-serif; font-size : 17px; background-color : rgb(25, 30, 30); }
body {
background: rgb(255,255,255);
}
.title { width : 1070px; margin : 20px auto; color : #000; margin-top : 30px; }
.title a, .title a:visited {color : #0080ff; position : relative;}
.container { width : 1200px; margin : 10px auto; border-radius: 20px; padding : 15px;  clear:both; }
#bio { height : 350px; position: relative; float : left; width : 700px; }
#me { border : 0 solid black; margin-bottom : 30px; border-radius : 20px; }
#sidebar { margin-right : 50px; border : 0 solid black; float : left; margin-bottom : 0;}
a { text-decoration : none; }
a:hover { text-decoration : underline; }
a, a:visited { color : #0080ff; }
.publogo { margin-right : 20px; float : left; border : 0;}
.publication { clear : left; padding-bottom : 3px; }
.publication p { height : 100px; padding-top : 0px;}
.publication strong a { color : #000; }
.publication .links { position : relative; top : 15px }
.publication .links a { margin-right : 20px; }
.publication img { border-radius : 5px; }
.codelogo { margin-right : 50px; float : left; border : 0;}
.code { padding-bottom : 10px; vertical-align :middle; height : 150px !important; width : 550px;}
.code .download a { display : block; margin : 0 30px 0 0; float : left;}
.code strong { display : block; padding-bottom : 10px;}
.code strong a { color : #000; }
.code img { border-radius : 5px; }
.external a { margin : 0 10px; }
.external a.first { margin : 0 10px 0 0; }
</style>

<script type="text/javascript" src="//code.jquery.com/jquery-1.11.0.min.js"></script>
<script type="text/javascript" src="//code.jquery.com/jquery-migrate-1.2.1.min.js"></script>

<style>
* {
	outline:none;
 -webkit-box-sizing: border-box;
	-moz-box-sizing: border-box;
		 box-sizing: border-box;
}

html, body {min-height: 100vh;}

.timeline {
	width:800px;
	height: 20px;
	list-style: none;
	text-align: justify;
	position: relative;
	left: 50%;
	top: 50%;
	-webkit-transform: translate(-50%, -50%);
	   -moz-transform: translate(-50%, -50%);
	    -ms-transform: translate(-50%, -50%);
	     -o-transform: translate(-50%, -50%);
	        transform: translate(-50%, -50%);
	background: -moz-linear-gradient(top, rgba(255,255,255,0) 0%, rgba(255,255,255,0) 45%, rgba(255,255,255,1) 51%, rgba(255,255,255,0) 57%, rgba(255,255,255,0) 100%);
	background: -webkit-gradient(left top, left bottom, color-stop(0%, rgba(255,255,255,0)), color-stop(45%, rgba(255,255,255,0)), color-stop(51%, rgba(255,255,255,0)), color-stop(57%, rgba(255,255,255,0)), color-stop(100%, rgba(255,255,255,0)));
	background: -webkit-linear-gradient(top, rgba(255,255,255,0) 0%, rgba(255,255,255,0) 45%, rgba(255,255,255,1) 51%, rgba(255,255,255,0) 57%, rgba(255,255,255,0) 100%);
	background: -o-linear-gradient(top, rgba(255,255,255,0) 0%, rgba(255,255,255,0) 45%, rgba(255,255,255,1) 51%, rgba(255,255,255,0) 57%, rgba(255,255,255,0) 100%);
	background: -ms-linear-gradient(top, rgba(255,255,255,0) 0%, rgba(255,255,255,0) 45%, rgba(255,255,255,1) 51%, rgba(255,255,255,0) 57%, rgba(255,255,255,0) 100%);
	background: linear-gradient(to bottom, rgba(255,255,255,0) 0%, rgba(255,255,255,0) 45%, rgba(0,0,0,1) 51%, rgba(255,255,255,0) 57%, rgba(255,255,255,0) 100%);
}

.timeline:after {display: inline-block; content: ""; width: 100%;}

.timeline li {
	display: inline-block;
	width: 20px;
	height: 20px;
	background: #09795D;
	text-align: center;
	line-height: 1.2;
	position: relative;
	-webkit-border-radius: 50%;
	        border-radius: 50%;
}

.timeline li:before {
	display: inline-block;
	content: attr(data-year);
	font-size: 18px;
	position: absolute;
	left: 50%;
	-webkit-transform: translateX(-50%);
	   -moz-transform: translateX(-50%);
	    -ms-transform: translateX(-50%);
	     -o-transform: translateX(-50%);
	        transform: translateX(-50%);
}

.timeline li:nth-child(odd):before {
	top: -20px;
}
.timeline li:nth-child(even):before {
	top: -20px;
}

.timeline li:after {
	display: inline-block;
	content: attr(data-text);
	font-size: 16px;
	position: absolute;
	left: 50%;
	-webkit-transform: translateX(-50%);
	   -moz-transform: translateX(-50%);
	    -ms-transform: translateX(-50%);
	     -o-transform: translateX(-50%);
	        transform: translateX(-50%);
}

.timeline li:nth-child(odd):after {
	bottom: 0;
	margin-bottom: -5px;
	-webkit-transform: translate(-50%, 100%);
	   -moz-transform: translate(-50%, 100%);
	    -ms-transform: translate(-50%, 100%);
	     -o-transform: translate(-50%, 100%);
	        transform: translate(-50%, 100%);
}
.timeline li:nth-child(even):after {
	bottom: 0;
	margin-bottom: -5px;
	-webkit-transform: translate(-50%, 100%);
	   -moz-transform: translate(-50%, 100%);
	    -ms-transform: translate(-50%, 100%);
	     -o-transform: translate(-50%, 100%);
	        transform: translate(-50%, 100%);
}
</style>

</head>
<body>

<div class="title">
    <div id="bio">
        <div style="position:absolute;top:70px;">
            <p style="line-height:23px;">Eshed Ohn-Bar<br>
            <p style="line-height:23px;">Assistant Professor<br>
            Boston University<br>
            Email: <a href="mailto:eohnbar@gmail.com">eohnbar [at] gmail [dot] com</a></p>
			<img src="./images/H2Xlogo.svg" width="80%">
			<br>
            <!-- <p class="external"><a href="https://scholar.google.com/citations?user=p9zVBV4AAAAJ&hl=en&oi=ao">Google Scholar</a></p>
			<a href="eohnbar_cv.pdf" class="first">CV</a>&bull; !-->
            <a style="text-decoration: underline; text-underline: single" href="#About">About</a> |
    <a style="text-decoration: underline; text-underline: single" href="#News">News</a> |
    <a style="text-decoration: underline; text-underline: single" href="#Research">Research</a> |
	<a style="text-decoration: underline; text-underline: single" href="#People">People</a> |
	<a style="text-decoration: underline; text-underline: single" href="#Publications">Publications</a> |
	<a style="text-decoration: underline; text-underline: single" href="#ProfessionalActivity">Professional Activity</a> |
<a style="text-decoration: underline; text-underline: single" href="https://scholar.google.com/citations?user=p9zVBV4AAAAJ&hl=en&oi=ao">Scholar</a> 
<br>
        </div>
    </div>
       <div id="sidebar"> &#8287;  &#8287;  &#8287; <img src="images/fig_website.jpg" id="eshed" width="280" itemprop="photo" style="border-radius: 30px 30px 30px 30px; box-shadow: 0px 0px 10px #888;"  /></div>
</div>


<!-- In particular, we are interested in advancing the state-of-the-art of systems that can efficiently understand and adaptively interact with humans in their environment. 
      !-->
<div class="container">
    <a name="About"></a>
    <h2>About</h2>
	I am interested in machine intelligence for real-world, embodied, assistive and autonomous systems.
	At Boston University, I am heading the <strong>Human-to-Everything (H2X) Lab </strong>. 
	Our research spans multiple areas of real-world system design, from machine learning and perception to decision-making and human-machine interaction. 
	Through innovative algorithms and seamless human-machine platforms, our overarching goal is to develop intelligent technologies with robust autonomy and real-time assistance capabilities.
    We currently focus on data-driven perception, planning, and control systems ('X' in H2X) for safety-critical applications in <strong>navigation and transportation</strong>&ndash;including autonomous driving and assisted navigation to people with visual impairments. 
	<br>
	<br> 
	<strong>If you are interested in joining the lab to research machine learning and perception for intelligent and assistive systems, please email me your CV.</strong>  
</div>

<div class="container">
	<br>  
	<ul class="timeline">
	<a href="https://www.krafael.org.il/en/"><li data-year="2005" data-text="Rafael Village, Volunteer"></li></a>
	<li data-year="2010" data-text="UCLA, B.S. Math"></li>
	<a href="https://en.wikipedia.org/wiki/Theodore_Roosevelt_High_School_(Los_Angeles)"><li data-year="2011" data-text="Roosevelt High, Teacher"></li></a>
	<a href="https://www.apple.com/"><li data-year="2015" data-text="Apple, SPG"></li></a>
	<li data-year="2017" data-text="UCSD, Ph.D. EE"></li></a>
	<a href="http://www.cs.cmu.edu/~kkitani/"><li data-year="2018" data-text="CMU, Robotics Institute"></li></a>
	<a href="https://avg.is.tuebingen.mpg.de/"><li data-year="2019" data-text="MPI Intelligent Systems"></li></a>
	<a href="https://www.bu.edu/eng/profile/ohn-bar-eshed/"><li data-year="2020" data-text="H2X Lab, Boston University"></li></a>
</ul>
<br>
</div>


	<a name="News"></a>
<div class="container">
    <h2>News</h2>
   <ul>
<li>We are semifinalists in the DOT Inclusive Design Challenge! <a href="https://www.transportation.gov/briefing-room/us-department-transportation-announces-over-41-million-awards-innovative-technologies">Press release</a> &nbsp;  <a href="http://www.bu.edu/systems/2021/02/01/accessible-autonomous-vehicle-system-wins-semifinalist-position-in-dot-competition/">More info</a>
<li>Received a CISE grant for interactive learning of assistive systems.
<li>Rahul, Minglan, and Luca receive a UROP award.
<li>Best paper award at the Web for All conference! 
<li>Like challenging trajectory prediction problems? Check out the <a href="https://github.com/eshed1/PING">Github</a> from our CoRL paper.
<li>Received a Humboldt fellowship, visiting MPI and working with <a href = "http://www.cvlibs.net/">Andreas Geiger</a>.
<li>Talked about human-centered autonomous vehicles at the <a href="https://itspodcast.com/its-podcast-episode-46-aeromedical-transportation-hand-uber-aftermath-and-india-goes-electric/">ITS Podcast</a>.
<li>I am honored to have received the <a href="https://www.ieee-itss.org/awards-best-dissertation"> 2017 IEEE Intelligent Transportation Systems Society best PhD dissertation award</a>.
<li>Participated in the CVPR 2017 doctoral consortium.
<li>We are co-organizing the <a href="http://icvl.ee.ic.ac.uk/hands17/">3rd workshop on observing and understanding hands in action (HANDS)</a> at ICCV 2017.
<li>Gave at talk at the CMU VASC seminar about <a href="https://www.cs.cmu.edu/calendar/thu-2017-02-16-1500/vision-and-autonomous-systems-seminar">human-centered autonomous vehicles</a>.
<li>Best paper award runner-up at ICPR 2016</a>!
<li>Gave a keynote talk about hands and intelligent vehicles at the CVPR-HANDS workshop.
<li>We are co-organizing the 2nd workshop on observing and understanding hands in action (HANDS) at CVPR 2016.
<li>We are co-organizing the 1st workshop on observing and understanding hands in action (HANDS) at CVPR 2015.
<li>First place in the KITTI car detection and orientation estimation challenge at ECCV 2014!
<li>Best industry related paper award (BIRPA) runner up at ICPR 2014!
<li>Best paper award at the IEEE Workshop on Analysis and Modeling of Faces and Gestures (with CVPR, 2013)!
</div>

	

	<a name="Research"></a>
<div class="container">
    <h2>Research (click one)</h2>
    <br>
   <ul>
<div class="row">
<div class="pull-left" style="width:1.4%;">
&nbsp
</div>

      <div class="pull-left" style="width:29%;">
      <div class="box" style="width:100%;">
<div align="center">
    <a data-toggle="collapse" data-parent="#access" href="#access-info"><img width="97%" src="images/w41.png"></a>
</br>
</div>
</div>
<p style="margin:5px 0px 0px 0px;"></p>
<font style="font-size:18px; font-weight:500;"><a data-toggle="collapse" data-parent="#access" href="#access-info">Interactive Learning Systems</a></font>
</div>

<div class="pull-left" style="width:4%;">
&nbsp
</div>

      <div class="pull-left" style="width:29%;">
      <div class="box" style="width:100%;">
<div align="center">
    <a data-toggle="collapse" data-parent="#detection" href="#detection-info"><img width="100%" src="images/imp2.png"></a>
</br>
</div>
</div>
<p style="margin:5px 0px 0px 0px;"></p>
<font style="font-size:18px; font-weight:500;"><a data-toggle="collapse" data-parent="#detection" href="#detection-info">Machine Perception</a></font>
</div>

</div>

<div class="row">

<div class="pull-left" style="width:1.4%;">
&nbsp
</div>

      <div class="pull-left" style="width:29%;">
        <div class="box" style="width:100%;">
<div align="center">
<a data-toggle="collapse" data-parent="#behavior" href="#behavior-info">
          <img width="97%" style="margin-top:0.5px; margin-bottom:0.5px;" src="images/cviu.jpg">
          </a>
</br>
</div>
</div>
<p style="margin:5px 0px 0px 0px;"></p>
<font style="font-size:18px; font-weight:500;"><a data-toggle="collapse" data-parent="#behavior" href="#behavior-info">Computational Behavior Models</a></font>
</div>

<div class="pull-left" style="width:4%;">
&nbsp
</div>

      <div class="pull-left" style="width:29%;">
        <div class="box" style="width:100%;">
<div align="center">
         <a data-toggle="collapse" data-parent="#hand" href="#hand-info"><img width="100%" style="margin-top:5px; margin-bottom:5px;" src="images/beyond_small.png"></a>
</br>
</div>
</div>
<p style="margin:5px 0px 0px 0px;"></p>
<font style="font-size:18px; font-weight:500;"><a data-toggle="collapse" data-parent="#hand" href="#hand-info">Human-Machine Interfaces</a></font>
</div>
</div>


<!--<p style="margin:5px 0px 0px 0px;"></p>!-->
<p style="margin:5px 0px 0px 0px;"></p>
<div class="row">
<div class="pull-left" style="width:1.4%;"> <!-- 1.5%,0px !-->

</div>


<div id="access-info" class="panel-collapse collapse out" style="padding:0% 3% 1% 3%; border-radius:6px; border-style: solid; border-color: #666666;">

<p style="margin:10px 0px 0px 0px;"></p>
<font style="font-size:1.34em; font-weight:500;">Assisting Navigation of People with Visual Impairments</font><div class="pull-right" style="width:29%;"> <a data-toggle="collapse" data-parent="#access" href="#access-info">close window</a></div>
      <div class="media">
  <!--    <p align="justify">Object class detection information ("Intro" from phd pdf)-->

  <p style="margin:30px 0px 0px 0px;"></p>

      <h3>Relevant Publications</h3>

<br/>
<p style="margin:-10px 0px 0px 0px;"></p>

<font style="font-size:1.11em; font-weight:500;">Learning User Models for Assistive Navigation</font>
<br/>
<br/>




<p style="margin:-12px 0px 0px 0px;"></p>

		
	  <ul class="list-group">
      <li class="list-group-item" style="padding:0 0 0.2% 1.0%;">
<div class="media">
<div class="pull-left text-center" style="padding:11px 3.4% 0 0;">
   <a href="https://arxiv.org/pdf/1804.04118.pdf.pdf"><img width="300" src="images/pingc.png"></a>
</div>
   <br>
   <h4 style="font-size:18px; line-height:120%">Personalized Dynamics Models for Adaptive Assistive Navigation Systems</h4>
   <p style="margin:-8px 0px 0px 0px;"></p>
   <p style="font-size:18px" style="padding:0px 0px 0px 0px;"><strong>E. Ohn-Bar</strong>, K. Kitani, and C. Asakawa</p>
  <p style="margin:-10px 0px 0px 0px;"></p><p style="font-size:18px" style="padding:0px 0px 0px 0px;"> <em>2nd Conference on Robot Learning (<strong>CoRL</strong>), Proceedings of Machine Learning Research</em>, 2018</p>
   <p style="margin:-8px 0px 0px 0px;"></p>[<a href="https://arxiv.org/abs/1804.04118">pdf</a>]
</div>


  </li>
    </ul>
<p style="margin:-8px 0px 0px 0px;"></p>


  <ul class="list-group">
      <li class="list-group-item" style="padding:0 0 0.2% 1.0%;">
<div class="media">
<div class="pull-left text-center" style="padding:11px 3.4% 0 0;">
   <a href="papers/var_ubicomp.pdf"><img width="300" src="images/ubi.png"></a>
</div>
   <br>
   <h4 style="font-size:18px; line-height:120%">Variability in Reactions to Instructional Guidance during Smartphone-Based Assisted Navigation of Blind Users</h4>
   <p style="margin:-8px 0px 0px 0px;"></p>
   <p style="font-size:18px" style="padding:0px 0px 0px 0px;"><strong>E. Ohn-Bar</strong>, J. Guerreiro, K. Kitani, and C. Asakawa</p>
  <p style="margin:-10px 0px 0px 0px;"></p><p style="font-size:18px" style="padding:0px 0px 0px 0px;">In <em>International Joint Conference on Pervasive and Ubiquitous Computing (<strong>UbiComp / IMWUT</strong>)</em>, 2018</p>
  <!--  <p style="margin:-10px 0px 0px 0px;"></p><p style="font-size:18px" style="padding:0px 0px 0px 0px;"><font color="red">Zamperoni Award Nominee</font></p>-->
   <p style="margin:-8px 0px 0px 0px;"></p>[<a href="papers/var_ubicomp.pdf">pdf</a>]
</div>

  </li>
    </ul>
<p style="margin:-8px 0px 0px 0px;"></p>



    <ul class="list-group">
      <li class="list-group-item" style="padding:0 0 0.2% 1.0%;">
<div class="media">
<div class="pull-left text-center" style="padding:11px 3.4% 0 0;">
   <a href="papers/expertiseIUI.pdf"><img width="300" height = "220" src="images/expert.png"></a>
</div>
   <br>
   <h4 style="font-size:18px; line-height:120%">Modeling Expertise in Assistive Navigation Interfaces for Blind People</h4>
   <p style="margin:-8px 0px 0px 0px;"></p>
   <p style="font-size:18px" style="padding:0px 0px 0px 0px;"><strong>E. Ohn-Bar</strong>, J. Guerreiro, D. Ahmetovic, K. Kitani, and C. Asakawa</p>
   <p style="margin:-10px 0px 0px 0px;"></p><p style="font-size:18px" style="padding:0px 0px 0px 0px;">In <em>International Conference on Intelligent User Interfaces (<strong>IUI</strong>)</em>, 2018</p>
   <p style="margin:-8px 0px 0px 0px;"></p>[<a href="papers/expertiseIUI.pdf">pdf</a>]
</div>

  </li>
    </ul>
<p style="margin:-8px 0px 0px 0px;"></p>



  <ul class="list-group">
      <li class="list-group-item" style="padding:0 0 0.2% 1.0%;">
<div class="media">
<div class="pull-left text-center" style="padding:11px 3.4% 0 0;">
   <a href="papers/envfact.pdf"><img width="300" src="images/chi.png"></a>
</div>
   <br>
   <h4 style="font-size:18px; line-height:120%">Environmental Factors in Indoor Navigation Based on Real-World Trajectories of Blind Users</h4>
   <p style="margin:-8px 0px 0px 0px;"></p>
   <p style="font-size:18px" style="padding:0px 0px 0px 0px;">H. Kacorri, <strong>E. Ohn-Bar</strong>, K. Kitani, and C. Asakawa</p>
  <p style="margin:-10px 0px 0px 0px;"></p><p style="font-size:18px" style="padding:0px 0px 0px 0px;">In <em>Conference on Human Factors in Computing Systems (<strong>CHI</strong>)</em>, 2018</p>
  <!--  <p style="margin:-10px 0px 0px 0px;"></p><p style="font-size:18px" style="padding:0px 0px 0px 0px;"><font color="red">Zamperoni Award Nominee</font></p>-->
   <p style="margin:-8px 0px 0px 0px;"></p>[<a href="papers/envfact.pdf">pdf</a>]
</div>

  </li>
    </ul>
<p style="margin:-8px 0px 0px 0px;"></p>




<br>
<font style="font-size:1.11em; font-weight:500;">Vision for Wearable Cameras</font>
<br/>
<br/>
<p style="margin:-12px 0px 0px 0px;"></p>
    <ul class="list-group">
      <li class="list-group-item" style="padding:0 0 0.2% 1.0%;">
<div class="media">
<div class="pull-left text-center" style="padding:11px 3.4% 0 0;">
   <a href="papers/smartpartnet.pdf"><img width="300" height = "220" src="images/wacv.png"></a>
</div>
   <br>
   <h4 style="font-size:18px; line-height:120%">SmartPartNet: Part-Informed Person Detection for Body-Worn Smartphones</h4>
   <p style="margin:-8px 0px 0px 0px;"></p>
   <p style="font-size:18px" style="padding:0px 0px 0px 0px;">H. Yu, <strong>E. Ohn-Bar</strong>, D. Yoo, and K. Kitani</p>
   <p style="margin:-10px 0px 0px 0px;"></p><p style="font-size:18px" style="padding:0px 0px 0px 0px;">In <em>Winter Conf. on Applications of Computer Vision (<strong>WACV</strong>)</em>, 2018<br></p>
   <p style="margin:-8px 0px 0px 0px;"></p>[<a href="papers/smartpartnet.pdf">pdf</a>]
</div>
      </li>
    </ul>
<p style="margin:-8px 0px 0px 0px;"></p>

      <a data-toggle="collapse" data-parent="#access" href="#access-info">close window</a>
      </div>
      </div>


<div id="detection-info" class="panel-collapse collapse out" style="padding:0% 3% 1% 3%; border-radius:6px; border-style: solid; border-color: #666666;">

<p style="margin:10px 0px 0px 0px;"></p>
<font style="font-size:1.34em; font-weight:500;">Contextual Visual Scene Understanding</font><div class="pull-right" style="width:29%;"> <a data-toggle="collapse" data-parent="#detection" href="#detection-info">close window</a></div>
      <div class="media">
  <!--    <p align="justify">Object class detection information ("Intro" from phd pdf)-->

  <p style="margin:30px 0px 0px 0px;"></p>

      <h3>Relevant Publications</h3>

<br/>
<p style="margin:-10px 0px 0px 0px;"></p>

<font style="font-size:1.11em; font-weight:500;">Human-Centered Visual Recognition</font>
<br/>
<br/>
<p style="margin:-12px 0px 0px 0px;"></p>
    <ul class="list-group">
      <li class="list-group-item" style="padding:0 0 0.2% 1.0%;">
<div class="media">
<div class="pull-left text-center" style="padding:11px 3.4% 0 0;">
   <a href="papers/areall.pdf"><img width="300" height = "220" src="images/imp2.png"></a>
</div>
   <br>
   <h4 style="font-size:18px; line-height:120%">Are All Objects Equal? Deep Spatio-Temporal Importance Prediction in Driving Videos</h4>
   <p style="margin:-8px 0px 0px 0px;"></p>
   <p style="font-size:18px" style="padding:0px 0px 0px 0px;"><strong>E. Ohn-Bar</strong> and M. Trivedi</p>
   <p style="margin:-10px 0px 0px 0px;"></p><p style="font-size:18px" style="padding:0px 0px 0px 0px;">In <em>Pattern Recognition</em> (<strong>PR</strong>), 2017</p>
   <p style="margin:-8px 0px 0px 0px;"></p>[<a href="papers/areall.pdf">pdf</a>]
</div>

  </li>
    </ul>
<p style="margin:-8px 0px 0px 0px;"></p>

  <ul class="list-group">
      <li class="list-group-item" style="padding:0 0 0.2% 1.0%;">
<div class="media">
<div class="pull-left text-center" style="padding:11px 3.4% 0 0;">
   <a href="papers/imp_icpr.pdf"><img width="300" src="images/imp2a.png"></a>
</div>
   <br>
   <h4 style="font-size:18px; line-height:120%">What Makes an On-road Object Important?</h4>
   <p style="margin:-8px 0px 0px 0px;"></p>
   <p style="font-size:18px" style="padding:0px 0px 0px 0px;"><strong>E. Ohn-Bar</strong> and M. Trivedi</p>
  <p style="margin:-10px 0px 0px 0px;"></p><p style="font-size:18px" style="padding:0px 0px 0px 0px;">In <em>International Conference on Pattern Recognition</em> (<strong>ICPR</strong>), 2016 (oral)</p>
  <b><font color="red">Best student paper award finalist</font></b><br>
  <!--  <p style="margin:-10px 0px 0px 0px;"></p><p style="font-size:18px" style="padding:0px 0px 0px 0px;"><font color="red">Zamperoni Award Nominee</font></p>-->
   <p style="margin:-8px 0px 0px 0px;"></p>[<a href="papers/imp_icpr.pdf">pdf</a>]
</div>

  </li>
    </ul>
<p style="margin:-8px 0px 0px 0px;"></p>

<br>
<font style="font-size:1.11em; font-weight:500;">Contextual Object Detection</font>
<br/>
<br/>
<p style="margin:-12px 0px 0px 0px;"></p>
    <ul class="list-group">
      <li class="list-group-item" style="padding:0 0 0.2% 1.0%;">
<div class="media">
<div class="pull-left text-center" style="padding:11px 3.4% 0 0;">
   <a href="papers/mss_PR.pdf"><img width="300" height = "220" src="images/outofbox.png"></a>
</div>
   <br>
   <h4 style="font-size:18px; line-height:120%">Multi-scale Volumes for Deep Object Detection and Localization</h4>
   <p style="margin:-8px 0px 0px 0px;"></p>
   <p style="font-size:18px" style="padding:0px 0px 0px 0px;"><strong>E. Ohn-Bar</strong> and M. Trivedi</p>
   <p style="margin:-10px 0px 0px 0px;"></p><p style="font-size:18px" style="padding:0px 0px 0px 0px;">In <em>Pattern Recognition</em> (<strong>PR</strong>), 2016</p>
   <p style="margin:-8px 0px 0px 0px;"></p>[<a href="papers/mss_PR.pdf">pdf</a>]
</div>
      </li>
    </ul>
<p style="margin:-8px 0px 0px 0px;"></p>

<!--
<p style="margin:-12px 0px 0px 0px;"></p>
    <ul class="list-group">
      <li class="list-group-item" style="padding:0 0 0.2% 1.0%;">
<div class="media">
<div class="pull-left text-center" style="padding:11px 3.4% 0 0;">
   <a href="papers/refinenet_TIV.pdf"><img width="300" height = "220" src="images/refinenet.png"></a>
</div>
   <br>
   <h4 style="font-size:18px; line-height:120%">RefineNet: Iterative Refinement for Accurate Object Localization</h4>
   <p style="margin:-8px 0px 0px 0px;"></p>
   <p style="font-size:18px" style="padding:0px 0px 0px 0px;">R. N. Rajaram, <strong>E. Ohn-Bar</strong> and M. Trivedi</p>
   <p style="margin:-10px 0px 0px 0px;"></p><p style="font-size:18px" style="padding:0px 0px 0px 0px;">In <em>Submitted to IEEE Transactions on Intelligent Vehicles</em> (<strong>T-IV</strong>), 2016</p>
   <p style="margin:-8px 0px 0px 0px;"></p>[<a href="papers/refinenet_TIV.pdf">pdf</a>]
</div>
      </li>
    </ul>
<p style="margin:-8px 0px 0px 0px;"></p>
!-->

    <ul class="list-group">
      <li class="list-group-item" style="padding:0 0 0.2% 1.0%;">
<div class="media">
<div class="pull-left text-center" style="padding:11px 3.4% 0 0;">
   <a href="papers/OhnBar_TITS15_wsupplement.pdf"><img width="300" src="images/subcat2.png"></a>
</div>
   <h4 style="font-size:18px; line-height:120%">Learning to Detect Vehicles by Clustering Appearance Patterns</h4>
   <p style="margin:-8px 0px 0px 0px;"></p>
   <p style="font-size:18px" style="padding:0px 0px 0px 0px;"><strong>E. Ohn-Bar</strong> and M. Trivedi</p>
   <p style="margin:-10px 0px 0px 0px;"></p><p style="font-size:18px" style="padding:0px 0px 0px 0px;">In <em>IEEE Transactions on Intelligent Transportation Systems</em> (<strong>T-ITS</strong>), 2015</p>
   <p style="margin:-8px 0px 0px 0px;"></p>[<a href="papers/OhnBar_TITS15_wsupplement.pdf">pdf</a>]
</div>
      </li>
    </ul>
<p style="margin:-8px 0px 0px 0px;"></p>

   <ul class="list-group">
      <li class="list-group-item" style="padding:0 0 0.2% 1.0%;">
<div class="media">
<div class="pull-left text-center" style="padding:11px 3.4% 0 0;">
   <a href="papers/boostornot.pdf"><img width="300" src="images/boostold.png"></a>
</div>
   <br>
   <h4 style="font-size:18px; line-height:120%">To Boost or Not to Boost? On the Limits of Boosted Trees for Object Detection</h4>
   <p style="margin:-8px 0px 0px 0px;"></p>
   <p style="font-size:18px" style="padding:0px 0px 0px 0px;"><strong>E. Ohn-Bar</strong> and M. Trivedi</p>
   <p style="margin:-10px 0px 0px 0px;"></p><p style="font-size:18px" style="padding:0px 0px 0px 0px;">In <em>International Conference on Pattern Recognition</em> (<strong>ICPR</strong>), 2016 (oral)</p>
   <b><font color="red">Best student paper award finalist</font></b><br>
   <p style="margin:-8px 0px 0px 0px;"></p>[<a href="papers/boostornot.pdf">pdf</a>]
</div>
      </li>
    </ul>
    <p style="margin:-8px 0px 0px 0px;"></p>
<!-- note that it also selects more context stuff around the peds -->

   <ul class="list-group">
      <li class="list-group-item" style="padding:0 0 0.2% 1.0%;">
<div class="media">
<div class="pull-left text-center" style="padding:11px 3.4% 0 0;">
   <a href="papers/mss_icpr.pdf"><img width="300" src="images/mss.png"></a>
</div>
   <br>
   <h4 style="font-size:18px; line-height:120%">Detection and Localization with Multi-scale Models</h4>
   <p style="margin:-8px 0px 0px 0px;"></p>
   <p style="font-size:18px" style="padding:0px 0px 0px 0px;"><strong>E. Ohn-Bar</strong> and M. Trivedi</p>
   <p style="margin:-10px 0px 0px 0px;"></p><p style="font-size:18px" style="padding:0px 0px 0px 0px;">In <em>International Conference on Pattern Recognition</em> (<strong>ICPR</strong>), 2016 (oral)</p>
   <p style="margin:-8px 0px 0px 0px;"></p>[<a href="papers/mss_icpr.pdf">pdf</a>]
</div>
      </li>
    </ul>

      <a data-toggle="collapse" data-parent="#detection" href="#detection-info">close window</a>
      </div>
      </div>


      <div id="behavior-info" class="panel-collapse collapse out" style="padding:0% 3% 1% 3%; border-radius:6px; border-style: solid; border-color: #666666;">

<p style="margin:10px 0px 0px 0px;"></p>
<font style="font-size:1.34em; font-weight:500;">Multi-modal Behavior Modeling</font><div class="pull-right" style="width:29%;"> <a data-toggle="collapse" data-parent="#behavior" href="#behavior-info">close window</a></div>
      <div class="media">
    <!--    <p align="justify">Object class detection information ("Intro" from phd pdf)-->

  <p style="margin:30px 0px 0px 0px;"></p>

      <h3>Relevant Publications</h3>

<br/>
<p style="margin:-10px 0px 0px 0px;"></p>


<font style="font-size:1.11em; font-weight:500;">Humans and Autonomous Vehicles</font>
<br/>
<br/>
<p style="margin:-12px 0px 0px 0px;"></p>
    <ul class="list-group">
      <li class="list-group-item" style="padding:0 0 0.2% 1.0%;">
<div class="media">
<div class="pull-left text-center" style="padding:11px 3.4% 0 0;">
   <a href="papers/humansTIV.pdf"><img width="300" height = "220" src="images/humansTIV.png"></a>
</div>
   <br></br><br>
   <h4 style="font-size:18px; line-height:120%">Looking at Humans in the Age of Self-Driving and Highly Automated Vehicles</h4> 
   <p style="margin:-8px 0px 0px 0px;"></p>
   <p style="font-size:18px" style="padding:0px 0px 0px 0px;"><strong>E. Ohn-Bar</strong> and M. Trivedi</p>
   <p style="margin:-10px 0px 0px 0px;"></p><p style="font-size:18px" style="padding:0px 0px 0px 0px;">In <em>IEEE Transactions on Intelligent Vehicles</em> (<strong>T-IV</strong>), 2016</p>
   <p style="margin:-8px 0px 0px 0px;"></p>[<a href="papers/humansTIV.pdf">pdf</a>]
</div>
  </li>
    </ul>
<p style="margin:-8px 0px 0px 0px;"></p>

<br>
<font style="font-size:1.11em; font-weight:500;">Multi-Cue Driver Behavior Prediction</font>
<br/>
<br/>
<p style="margin:-12px 0px 0px 0px;"></p>
    <ul class="list-group">
      <li class="list-group-item" style="padding:0 0 0.2% 1.0%;">
<div class="media">
<div class="pull-left text-center" style="padding:11px 3.4% 0 0;">
   <a href="papers/CVIUpredict.pdf"><img width="300" height = "220" src="images/cviu.jpg"></a>
</div>
   <br>
   <h4 style="font-size:18px; line-height:120%">On Surveillance for Safety Critical Events: In-Vehicle Video Networks for Predictive Driver Assistance Systems</h4>
   <p style="margin:-8px 0px 0px 0px;"></p>
   <p style="font-size:18px" style="padding:0px 0px 0px 0px;"><strong>E. Ohn-Bar</strong>, A. Tawari, S. Martin, and M. Trivedi</p>
   <p style="margin:-10px 0px 0px 0px;"></p><p style="font-size:18px" style="padding:0px 0px 0px 0px;">In <em>Computer Vision and Image Understanding</em> (<strong>CVIU</strong>), 2015</p>
   <p style="margin:-8px 0px 0px 0px;"></p>[<a href="papers/CVIUpredict.pdf">pdf</a>]
</div>

  </li>
    </ul>
<p style="margin:-8px 0px 0px 0px;"></p>

 <ul class="list-group">
      <li class="list-group-item" style="padding:0 0 0.2% 1.0%;">
<div class="media">
<div class="pull-left text-center" style="padding:11px 3.4% 0 0;">
   <a href="papers/headhandeye.pdf"><img width="300" height = "220" src="images/conceptHeadHand.png"></a>
</div>
   <h4 style="font-size:18px; line-height:120%">Head, Eye, and Hand Patterns for Driver Activity Recognition</h4>
   <p style="margin:-8px 0px 0px 0px;"></p>
   <p style="font-size:18px" style="padding:0px 0px 0px 0px;"><strong>E. Ohn-Bar</strong>, S. Martin, A. Tawari, and M. Trivedi</p>
   <p style="margin:-10px 0px 0px 0px;"></p><p style="font-size:18px" style="padding:0px 0px 0px 0px;">In <em>IEEE International Conference on Pattern Recognition</em> (<strong>ICPR</strong>), 2014 (oral)</p>
   <p style="margin:-10px 0px 0px 0px;"></p><p style="font-size:18px" style="padding:0px 0px 0px 0px;"><font color="red">Best Industry Related Paper - Runner Up</font></p>
   <p style="margin:-8px 0px 0px 0px;"></p>[<a href="papers/headhandeye.pdf">pdf</a>]
</div>
  </li>
    </ul>
<p style="margin:-8px 0px 0px 0px;"></p>

<br>
<font style="font-size:1.11em; font-weight:500;">Activity Modeling</font>
 <ul class="list-group">
      <li class="list-group-item" style="padding:0 0 0.2% 1.0%;">
<div class="media">
<div class="pull-left text-center" style="padding:11px 3.4% 0 0;">
   <a href="papers/OhnBarHAU3D13.pdf"><img width="300" height = "220" src="images/jas2_v.png"></a>
</div>
<br></br>
   <h4 style="font-size:18px; line-height:120%">Joint Angles Similarities and HOG2 for Action Recognition</h4>
   <p style="margin:-8px 0px 0px 0px;"></p>
   <p style="font-size:18px" style="padding:0px 0px 0px 0px;"><strong>E. Ohn-Bar</strong> and M. Trivedi</p>
   <p style="margin:-10px 0px 0px 0px;"></p><p style="font-size:18px" style="padding:0px 0px 0px 0px;">In <em>Human Activity Understanding from 3D Data Workshop, IEEE Conf. Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2013 (oral)</p>
  <p style="margin:-8px 0px 0px 0px;"></p>[<a href="papers/OhnBarHAU3D13.pdf">pdf</a>]
</div>
  </li>
    </ul>
<p style="margin:-8px 0px 0px 0px;"></p>

      <a data-toggle="collapse" data-parent="#behavior" href="#behavior-info">close window</a>
      </div>
      </div>


      <div id="hand-info" class="panel-collapse collapse out" style="padding:0% 3% 1% 3%; border-radius:6px; border-style: solid; border-color: #666666;">
<p style="margin:10px 0px 0px 0px;"></p>
<font style="font-size:1.34em; font-weight:500;">Hand Gestures and Interactivity</font><div class="pull-right" style="width:29%;"> <a data-toggle="collapse" data-parent="#hand" href="#hand-info">close window</a></div>
      <div class="media">
  <!--    <p align="justify">Object class detection information ("Intro" from phd pdf)-->

  <p style="margin:30px 0px 0px 0px;"></p>

      <h3>Relevant Publications</h3>
<br/>
<p style="margin:-10px 0px 0px 0px;"></p>


<br>
<font style="font-size:1.11em; font-weight:500;">In-Vehicle Hand Gestures</font>
<br/>
<br/>
<p style="margin:-12px 0px 0px 0px;"></p>

    <ul class="list-group">
      <li class="list-group-item" style="padding:0 0 0.2% 1.0%;">
<div class="media">
<div class="pull-left text-center" style="padding:11px 3.4% 0 0;">
   <a href="papers/OhnBar_IEEETITS2014.pdf"><img width="300" height = "220" src="images/itshands.png"></a>
</div><br>
   <h4 style="font-size:18px; line-height:120%">Hand Gesture Recognition in Real-Time for Automotive Interfaces: A Multimodal Vision-based Approach and Evaluations</h4>
   <p style="margin:-8px 0px 0px 0px;"></p>
   <p style="font-size:18px" style="padding:0px 0px 0px 0px;"><strong>E. Ohn-Bar</strong>, and M. Trivedi</p>
   <p style="margin:-10px 0px 0px 0px;"></p><p style="font-size:18px" style="padding:0px 0px 0px 0px;">In <em>IEEE Transactions on Intelligent Transportation Systems</em> (<strong>T-ITS</strong>), 2014</p>
   <p style="margin:-8px 0px 0px 0px;"></p>[<a href="papers/OhnBar_IEEETITS2014.pdf">pdf</a>]
</div>
  </li>
    </ul>
<p style="margin:-8px 0px 0px 0px;"></p>

    <ul class="list-group">
      <li class="list-group-item" style="padding:0 0 0.2% 1.0%;">
<div class="media">
<div class="pull-left text-center" style="padding:11px 3.4% 0 0;">
   <a href="papers/OhnBar_IV15_hands.pdf"><img width="300" height = "220" src="images/handscomp.png"></a>
</div>
   <h4 style="font-size:18px; line-height:120%">A Comparative Study of Color and Depth Features for Hand Gesture Recognition in Naturalistic Driving Settings</h4>
   <p style="margin:-8px 0px 0px 0px;"></p>
   <p style="font-size:18px" style="padding:0px 0px 0px 0px;"><strong>E. Ohn-Bar</strong>, and M. Trivedi</p>
   <p style="margin:-10px 0px 0px 0px;"></p><p style="font-size:18px" style="padding:0px 0px 0px 0px;">In <em>IEEE Intelligent Vehicles Symposium</em> (<strong>IV</strong>), 2015</p>
   <p style="margin:-8px 0px 0px 0px;"></p>[<a href="papers/OhnBar_IV15_hands.pdf">pdf</a>]
</div>
  </li>
    </ul>
<p style="margin:-8px 0px 0px 0px;"></p>


    <ul class="list-group">
      <li class="list-group-item" style="padding:0 0 0.2% 1.0%;">
<div class="media">
<div class="pull-left text-center" style="padding:11px 3.4% 0 0;">
   <a href="papers/beyondHands.pdf"><img width="300" height = "220" src="images/beyond.png"></a>
</div>
<br></br>
   <h4 style="font-size:18px; line-height:120%">Beyond Just Keeping Hands on the Wheel: Towards Visual Interpretation of Driver Hand Motion Patterns</h4>
   <p style="margin:-8px 0px 0px 0px;"></p>
   <p style="font-size:18px" style="padding:0px 0px 0px 0px;"><strong>E. Ohn-Bar</strong>, and M. Trivedi</p>
   <p style="margin:-10px 0px 0px 0px;"></p><p style="font-size:18px" style="padding:0px 0px 0px 0px;">In <em>IEEE Conference on Intelligent Transportation Systems</em> (<strong>ITSC</strong>), 2014</p>
   <p style="margin:-8px 0px 0px 0px;"></p>[<a href="papers/beyondHands.pdf">pdf</a>]
</div>
  </li>
    </ul>
<p style="margin:-8px 0px 0px 0px;"></p>


 <ul class="list-group">
      <li class="list-group-item" style="padding:0 0 0.2% 1.0%;">
<div class="media">
<div class="pull-left text-center" style="padding:11px 3.4% 0 0;">
   <a href="papers/OhnBarAMFG13.pdf"><img width="300" height = "220" src="images/kinect2.png"></a>
</div><br></br>
   <h4 style="font-size:18px; line-height:120%">The Power is in Your Hands: 3D Analysis of Hand Gestures in Naturalistic Video</h4>
   <p style="margin:-8px 0px 0px 0px;"></p>
   <p style="font-size:18px" style="padding:0px 0px 0px 0px;"><strong>E. Ohn-Bar</strong>, and M. Trivedi</p>
   <p style="margin:-10px 0px 0px 0px;"></p><p style="font-size:18px" style="padding:0px 0px 0px 0px;">In <em>Analysis and Modeling of Faces and Gestures Workshop, IEEE Conf. Computer Vision and Pattern Recognition</em> (<strong>CVPR</strong>)</em>, 2013 (oral)</p>
  <p style="margin:-10px 0px 0px 0px;"></p><p style="font-size:18px" style="padding:0px 0px 0px 0px;"><font color="red">Best Paper Award</font></p>
  <p style="margin:-8px 0px 0px 0px;"></p>[<a href="papers/OhnBarAMFG13.pdf">pdf</a>]
</div>
  </li>
    </ul>
<p style="margin:-8px 0px 0px 0px;"></p>


 <ul class="list-group">
      <li class="list-group-item" style="padding:0 0 0.2% 1.0%;">
<div class="media">
<div class="pull-left text-center" style="padding:11px 3.4% 0 0;">
   <a href="papers/hand_JEI13.pdf"><img width="300" height = "220" src="images/jei.png"></a>
</div><br>
   <h4 style="font-size:18px; line-height:120%">Driver Hand Activity Analysis in Naturalistic Driving Studies: Issues, Algorithms and Experimental Studies</h4>
   <p style="margin:-8px 0px 0px 0px;"></p>
   <p style="font-size:18px" style="padding:0px 0px 0px 0px;"><strong>E. Ohn-Bar</strong>, S. Martin, and M. Trivedi</p>
   <p style="margin:-10px 0px 0px 0px;"></p><p style="font-size:18px" style="padding:0px 0px 0px 0px;">In <em>Journal of Electronic Imaging: Special Section on Video Surveillance and Transportation Imaging Applications</em> (<strong>JEI</strong>), 2013</p>
  <p style="margin:-8px 0px 0px 0px;"></p>[<a href="papers/hand_JEI13.pdf">pdf</a>]
</div>
  </li>
    </ul>
<p style="margin:-8px 0px 0px 0px;"></p>

<br>
<font style="font-size:1.11em; font-weight:500;">Hand Detection and Tracking</font>
<br/>
<br/>
<p style="margin:-12px 0px 0px 0px;"></p>
    <ul class="list-group">
      <li class="list-group-item" style="padding:0 0 0.2% 1.0%;">
<div class="media">
<div class="pull-left text-center" style="padding:11px 3.4% 0 0;">
   <a href="papers/Rangesh_T_ITS_2016.pdf"><img width="300" height = "220" src="images/handtrack_b.png"></a>
</div>
   <br>
   <h4 style="font-size:18px; line-height:120%">Long-term, Multi-Cue Tracking of Hands in Vehicles</h4>
   <p style="margin:-8px 0px 0px 0px;"></p>
   <p style="font-size:18px" style="padding:0px 0px 0px 0px;">A. Rangesh, <strong>E. Ohn-Bar</strong>, and M. Trivedi</p>
   <p style="margin:-10px 0px 0px 0px;"></p><p style="font-size:18px" style="padding:0px 0px 0px 0px;">In <em>IEEE Transactions on Intelligent Transportation Systems</em> (<strong>T-ITS</strong>), 2016</p>
   <p style="margin:-8px 0px 0px 0px;"></p>[<a href="papers/Rangesh_T_ITS_2016.pdf">pdf</a>]
</div>
  </li>
    </ul>
<p style="margin:-8px 0px 0px 0px;"></p>

    <ul class="list-group">
      <li class="list-group-item" style="padding:0 0 0.2% 1.0%;">
<div class="media">
<div class="pull-left text-center" style="padding:11px 3.4% 0 0;">
   <a href="papers/Das_ITSC2015.pdf"><img width="300" height = "220" src="images/viva.png"></a>
</div>
   <br>
   <h4 style="font-size:18px; line-height:120%">On Performance Evaluation of Driver Hand Detection Algorithms: Challenges, Dataset, and Metrics</h4>
   <p style="margin:-8px 0px 0px 0px;"></p>
   <p style="font-size:18px" style="padding:0px 0px 0px 0px;">N. Das, <strong>E. Ohn-Bar</strong>, and M. Trivedi</p>
   <p style="margin:-10px 0px 0px 0px;"></p><p style="font-size:18px" style="padding:0px 0px 0px 0px;">In <em>IEEE Conference on Intelligent Transportation Systems</em> (<strong>ITSC</strong>), 2015</p>
   <p style="margin:-8px 0px 0px 0px;"></p>[<a href="papers/Das_ITSC2015.pdf">pdf</a>]
</div>
  </li>
    </ul>
<p style="margin:-8px 0px 0px 0px;"></p>
      <a data-toggle="collapse" data-parent="#hand" href="#hand-info">close window</a>
      </div>
      </div>
</div>
</div>



<div class="container">
	<a name="People"></a>
	<h2>People</h2>
	<ul>
	<li>Jimuyang (Jim) Zhang
	<li>Matthew Boyd
	<li>Andres Armijos
	<li>Minglan Zheng
	<li>Luca Guidi
	<li>Ameera Iftekhar
	<li>Jake Hellman
	<li>Hussain Valiuddin
	<li>Yuqi Zhu
	<li>Rahul Rajaram
	<li>Saahil Sood
	<li>Soumya Suman
	</ul>
</div>
	


<div class="container">
	<a name="Publications"></a>
<h2>Publications <a style="text-decoration: underline; text-underline: single" href="#2020">2020</a> | <a style="text-decoration: underline; text-underline: single" href="#2019">2019</a> | <a style="text-decoration: underline; text-underline: single" href="#2018">2018</a> | <a style="text-decoration: underline; text-underline: single" href="#2017">2017</a> | <a style="text-decoration: underline; text-underline: single" href="#2016">2016</a> | <a style="text-decoration: underline; text-underline: single" href="#2015">2015</a> |
    <a style="text-decoration: underline; text-underline: single" href="#2014">2014</a> |
	<a style="text-decoration: underline; text-underline: single" href="#2013">2013</a></h2>

	<a name="2020">2020</a> <hr style="height:3px;border:none;color:#808080;background-color:#808080;margin-top: -12px;margin-left: 50px;top: 50%;width: 100%;content: "";display: inline-block;"/>

<div class="publication">
	    <a href="./papers/Behl2020IROS.pdf"><img src="./images/Behl2020IROS.png" class="publogo" width="150" height ="110"></a>
	    <p><strong><a href="./papers/Behl2020IROS.pdf">Label Efficient Visual Abstractions for Autonomous Driving</a></strong><br>
	    A. Behl, K. Chitta, A. Prakash, E. Ohn-Bar, and A. Geiger<br>
	    <em>International Conference on Intelligent Robots and Systems (<strong>IROS</strong>)</em>, 2020<br>
    </div>
	
<div class="publication">
	    <a href="./papers/Ohn-Bar2020CVPR.pdf"><img src="./images/intro.png" class="publogo" width="150" height ="110"></a>
	    <p><strong><a href="./papers/Ohn-Bar2020CVPR.pdf">Learning Situational Driving</a></strong><br>
	    E. Ohn-Bar, A. Prakash, A. Behl, K. Chitta, and A. Geiger<br>
	    <em>Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2020<br>
    </div>
	
	<div class="publication">
	    <a href="./papers/Prakash2020CVPR.pdf"><img src="./images/prakash.png" class="publogo" width="150" height ="110"></a>
	    <p><strong><a href="./papers/Prakash2020CVPR.pdf">Exploring Data Aggregation in Policy Learning for Vision-based Urban Autonomous Driving</a></strong><br>
	    A. Prakash, A. Behl, E. Ohn-Bar, K. Chitta, and A. Geiger<br>
	    <em>Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2020<br>
    </div>
	
	<div class="publication">
	    <a href="./papers/guerreiro2020virtual.pdf"><img src="./images/ijhcs.png" class="publogo" width="150" height ="110"></a>
	    <p><strong><a href="./papers/guerreiro2020virtual.pdf">Virtual Navigation for Blind People: Transferring Route Knowledge to the Real-World</a></strong><br>
	    J. Guerreiro, D. Sato, D. Ahmetovic, E. Ohn-Bar, K. Kitani, and C. Asakawa<br>
	    <em>International Journal of Human-Computer Studies (<strong>IJHCS</strong>)</em>, 2020<br>
    </div>
	
	
	<div class="publication">
	    <a href="./papers/Higuchi2020.pdf"><img src="./images/tiis4.png" class="publogo" width="150" height ="110"></a>
	    <p><strong><a href="./papers/Higuchi2020.pdf">Learning Context-Dependent Personal Preferences for Adaptive Recommendation</a></strong><br>
	    K. Higuchi, H. Tsuchida, E. Ohn-Bar, Y. Sato, and K. Kitani<br>
	    <em>ACM Transaction on Interactive Intelligent Systems (<strong>T-IIS</strong>)</em>, 2020<br>
    </div>
	
<a name="2019">2019</a> <hr style="height:3px;border:none;color:#808080;background-color:#808080;margin-top: -12px;margin-left: 50px;top: 50%;width: 100%;content: "";display: inline-block;"/>

<div class="publication">
	    <a href="./papers/aexp4_IROS19.pdf"><img src="./images/aexp4a.png" class="publogo" width="150" height ="110"></a>
	    <p><strong><a href="./papers/aexp4_IROS19.pdf">A-EXP4: Online Social Policy Learning for Adaptive Robot-Pedestrian Interaction</a></strong><br>
	    P. Jin, <strong>E. Ohn-Bar</strong>, K. Kitani, and C. Asakawa<br>
	    <em>International Conference on Intelligent Robots and Systems (<strong>IROS</strong>)</em>, 2019<br>
		[<a href="./papers/aexp4_IROS19.pdf">pdf</a> | <a href="./papers/aexp4.txt">bibtex</a>]
    </div>
	<br>
	
 <div class="publication">
	    <a href="./papers/Time2Col_IROS19.pdf"><img src="./images/p.jpg" class="publogo" width="150" height ="110"></a>
	    <p><strong><a href="./papers/Time2Col_IROS19.pdf">Forecasting Time-To-Collision from Monocular Video: Feasibility, Dataset, and Challenges</a></strong><br>
	    A. Manglik, X. Weng, <strong>E. Ohn-Bar</strong>, and K. Kitani<br>
	    <em>International Conference on Intelligent Robots and Systems (<strong>IROS</strong>)</em>, 2019<br>
		[<a href="./papers/Time2Col_IROS19.pdf">pdf</a> | <a href="https://www.youtube.com/watch?v=I0cw872DXLg">demo</a> | <a href="https://github.com/aashi7/NearCollision">code</a> | <a href="https://aashi7.github.io/NearCollision.html">project</a> | <a href="./papers/collision.txt">bibtex</a>]
    </div>
	<br>
	
		 <div class="publication">
	    <a href="./papers/peds_RSS.pdf"><img src="./images/pedst.png" class="publogo" width="150" height ="110"></a>
	    <p><strong><a href="./papers/peds_RSS.pdf">Towards Understanding Interaction of Visually Impaired Navigators with Surrounding Pedestrians</a></strong><br>
	    <strong>E. Ohn-Bar</strong>, J. Guerreiro, D. Ahmetovic, K. Kitani, and C. Asakawa<br>
	    <em>H-Augmented Workshop, Robotics: Science and Systems (<strong>RSS</strong>)</em>, 2019<br>
		[<a href="./papers/peds_RSS.pdf">pdf</a> | <a href="./papers/peds_RSS.txt">bibtex</a>]
    </div>
	<br>
	<br>
	
	
		 <div class="publication">
	    <a href="https://www.researchgate.net/publication/331876129_Impact_of_Expertise_on_Interaction_Preferences_for_Navigation_Assistance_of_Visually_Impaired_Individuals"><img src="./images/w4.png" class="publogo" width="150" height ="110"></a>
	    <p><strong><a href="https://www.researchgate.net/publication/331876129_Impact_of_Expertise_on_Interaction_Preferences_for_Navigation_Assistance_of_Visually_Impaired_Individuals">Impact of Expertise on Interaction Preferences for Navigation Assistance of Visually Impaired Individuals</a></strong><br>
	    D. Ahmetovic, J. Guerreiro, <strong>E. Ohn-Bar</strong>, K. Kitani, and C. Asakawa<br>
	    <em>Web for All Conference (<strong>W4A</strong>)</em>, 2019<br>
		<font color="red"><strong>Best Paper Award</font></a></strong><br>
	    [<a href="https://www.researchgate.net/publication/331876129_Impact_of_Expertise_on_Interaction_Preferences_for_Navigation_Assistance_of_Visually_Impaired_Individuals">pdf</a> | <a href="./papers/w4a2019.txt">bibtex</a>]
    </div>
	
<a name="2018">2018</a> <hr style="height:3px;border:none;color:#808080;background-color:#808080;margin-top: -12px;margin-left: 50px;top: 50%;width: 100%;content: "";display: inline-block;"/>

		 <div class="publication">
	    <a href="https://arxiv.org/pdf/1804.04118.pdf"><img src="./images/pingc.png" class="publogo" width="150" height ="110"></a>
	    <p><strong><a href="https://arxiv.org/pdf/1804.04118.pdf">Personalized Dynamics Models for Adaptive Assistive Navigation Systems <font color="red"> (oral presentation)</font></a></strong><br>
	    <strong>E. Ohn-Bar</strong>, K. Kitani, and C. Asakawa<br>
	    <em>2nd Conference on Robot Learning (<strong>CoRL</strong>), Proceedings of Machine Learning Research</em>, 2018<font color="gray">  Acceptance rate: ~7%</font><br>
	    [<a href="https://arxiv.org/abs/1804.04118">pdf</a> | <a href="https://github.com/eshed1/PING">data </a> | <a href="./papers/ping.txt">bibtex</a>]
    </div>

	 <div class="publication">
	    <a href="./papers/var_ubicomp.pdf"><img src="./images/ubi.png" class="publogo" width="150" height ="110"></a>
	    <p><strong><a href="./papers/var_ubicomp.pdf">Variability in Reactions to Instructional Guidance during Smartphone-Based Assisted Navigation of Blind Users</a></strong><br>
	    <strong>E. Ohn-Bar</strong>, J. Guerreiro, K. Kitani, and C. Asakawa<br>
	    <em>International Joint Conference on Pervasive and Ubiquitous Computing (<strong>UbiComp / IMWUT</strong>)</em>, 2018<font color="gray">  Acceptance rate: ~20%</font><br>
	    [<a href="./papers/var_ubicomp.pdf">pdf</a> | <a href="./papers/variability_ubicomp.txt">bibtex</a>]
    </div>
	
	 <div class="publication">
	    <a href="https://arxiv.org/abs/1806.08479"><img src="./images/hiirl.png" class="publogo" width="150" height ="110"></a>
	    <p><strong><a href="https://arxiv.org/abs/1806.08479">Human-Interactive Subgoal Supervision for Efficient Inverse Reinforcement Learning</a></strong><br>
	    X. Pan, <strong>E. Ohn-Bar</strong>, N. Rhinehart, Y. Xu, Y. Shen, and K. M. Kitani<br>
	    <em>International Conference on Autonomous Agents and Multiagent Systems (<strong>AAMAS</strong>)</em>, 2018<font color="gray">  Acceptance rate: 25%</font><br>
	    [<a href="https://arxiv.org/abs/1806.08479">pdf</a> | <a href="./papers/hiirl.txt">bibtex</a>]
    </div>

    <div class="publication">
	    <a href="./papers/userbehavior_w4a.pdf"><img src="./images/navcog.jpg" class="publogo" width="150" height ="110"></a>
	    <p><strong><a href="./papers/userbehavior_w4a.pdf">How Context and User Behavior Affect Indoor Navigation Assistance for Blind People</a></strong><br>
	    J. Guerreiro, <strong>E. Ohn-Bar</strong>, D. Ahmetovic, K. Kitani, and C. Asakawa<br>
	    <em>Web for All Conference (<strong>W4A</strong>)</em>, 2018<br>
	    [<a href="./papers/userbehavior_w4a.pdf">pdf</a> | <a href="./papers/userbehavior_w4a.txt">bibtex</a>]
    </div>

    <div class="publication">
	    <a href="./papers/ExpertiseIUI.pdf"><img src="./images/expert.png" class="publogo" width="150" height ="110"></a>
	    <p><strong><a href="./papers/ExpertiseIUI.pdf">Modeling Expertise in Assistive Navigation Interfaces for Blind People</a></strong><br>
	    <strong>E. Ohn-Bar</strong>, J. Guerreiro, D. Ahmetovic, K. Kitani, and C. Asakawa<br>
	    <em>International Conference on Intelligent User Interfaces (<strong>IUI</strong>)</em>, 2018<font color="gray">  Acceptance rate: 23%</font><br>
	    [<a href="./papers/ExpertiseIUI.pdf">pdf</a> | <a href="./papers/ExpertiseIUI.txt">bibtex</a>]
    </div>


    <div class="publication">
	    <a href="./papers/envfact.pdf"><img src="./images/chi.png" class="publogo" width="150" height ="110"></a>
	    <p><strong><a href="./papers/envfact.pdf">Environmental Factors in Indoor Navigation Based on Real-World Trajectories of Blind Users</a></strong><br>
	    H. Kacorri, <strong>E. Ohn-Bar</strong>, K. Kitani, and C. Asakawa<br>
	    <em>Conference on Human Factors in Computing Systems (<strong>CHI</strong>)</em>, 2018<font color="gray">  Acceptance rate: 26%</font><br>
	    [<a href="./papers/envfact.pdf">pdf</a> | <a href="./papers/envfact.txt">bibtex</a>]
    </div>

    <div class="publication">
	    <a href="./papers/smartpartnet.pdf"><img src="./images/wacv.png" class="publogo" width="150" height ="110"></a>
	    <p><strong><a href="./papers/smartpartnet.pdf">SmartPartNet: Part-Informed Person Detection for Body-Worn Smartphones</a></strong><br>
	    H. Yu, <strong>E. Ohn-Bar</strong>, D. Yoo, and K. Kitani<br>
	    <em>Winter Conf. on Applications of Computer Vision (<strong>WACV</strong>)</em>, 2018<font color="gray">  Acceptance rate: 37%</font><br>
	    [<a href="./papers/smartpartnet.pdf">pdf</a> | <a href="./papers/smartpartnet.txt">bibtex</a>]
    </div>
<br>
<a name="2017">2017</a> <hr style="height:3px;border:none;color:#808080;background-color:#808080;margin-top: -12px;margin-left: 50px;top: 50%;width: 100%;content: "";display: inline-block;"/>


    <div class="publication">
	    <a href="./papers/areall.pdf"><img src="./images/imp2.png" class="publogo" width="150" height ="110"></a>
	    <p><strong><a href="./papers/areall.pdf">Are All Objects Equal? Deep Spatio-Temporal Importance Prediction in Driving Videos</a></strong><br>
	    <strong>E. Ohn-Bar</strong> and M. Trivedi<br>
	    <em>Pattern Recognition (<strong>PR</strong>)</em>, 2017<font color="gray">  Impact factor: 5.898</font><br>
	    [<a href="./papers/areall.pdf">pdf</a> | <a href="https://github.com/eshed1/Object_Importance">data and code</a> | <a href="object_importance.html">project</a> | <a href="./papers/areall_PR.txt">bibtex</a>]
    </div>

     <div class="publication">
			<a href="./papers/refineNet.pdf"><img src="./images/RefineTIV.png" class="publogo" width="150" height="110"></a>
		    <p><strong><a href="./papers/refineNet.pdf">RefineNet: Refining Object Detectors for Autonomous Driving</a></strong><br>
			R. N. Rajaram, <strong>E. Ohn-Bar</strong>, and M. Trivedi<br>
			<em>IEEE Transactions on Intelligent Vehicles (<strong>T-IV</strong>)</em>, 2017<br>
			[<a href="./papers/refineNet.pdf">pdf</a> | <a href="./papers/refineNet.txt">bibtex</a>]
    </div>
	
	 <div class="publication">
	    <a href="./papers/Dissertation_Eshed.pdf"><img src="./images/phd.png" class="publogo" width="150" height ="110"></a>
	    <p><strong><a href="./papers/Dissertation_Eshed.pdf">Contextual Visual Object Recognition and Behavior Modeling for Human-Robot Interactivity</a></strong><br>
	    <strong>E. Ohn-Bar</strong><br>
	    <em>PhD Thesis</em>, 2017<br>
	    [<a href="./papers/Dissertation_Eshed.pdf">pdf</a>]
    </div>
	
	  <div class="publication">
	    <a href="./papers/mss_PR.pdf"><img src="./images/outofbox.png" class="publogo" width="150" height ="110"></a>
	    <p><strong><a href="./papers/mss_PR.pdf">Multi-scale Volumes for Deep Object Detection and Localization</a></strong><br>
	    <strong>E. Ohn-Bar</strong> and M. Trivedi<br>
	    <em>Pattern Recognition (<strong>PR</strong>)</em>, 2017<font color="gray">  Impact factor: 5.898</font><br>
	    [<a href="./papers/mss_PR.pdf">pdf</a> | <a href="contact.txt">data </a> | <a href="./papers/mss_PR.txt">bibtex</a>]
    </div>

<a name="2016">2016</a> <hr style="height:3px;border:none;color:#808080;background-color:#808080;margin-top: -12px;margin-left: 50px;top: 50%;width: 100%;content: "";display: inline-block;"/>

    <div class="publication">
	    <a href="./papers/humansTIV.pdf"><img src="./images/humansTIV.png" class="publogo" width="150" height ="110"></a>
	    <p><strong><a href="./papers/humansTIV.pdf">Looking at Humans in the Age of Self-Driving and Highly Automated Vehicles</a></strong><br>
	    <strong>E. Ohn-Bar</strong> and M. Trivedi<br>
	    <em>IEEE Transactions on Intelligent Vehicles (<strong>T-IV</strong>)</em>, 2016<br>
	    [<a href="./papers/humansTIV.pdf">pdf</a> | <a href="./papers/humansTIV.txt">bibtex</a>]
    </div>

   <div class="publication">
     <a href="papers/Rangesh_T_ITS_2016.pdf"><img width="150" height = "110" class="publogo" src="images/handtrack_b.png"></a>
	<!--    <a href="./papers/Rangesh_T_ITS_2016.pdf"><img src="./images/handtrack.png" class="publogo" width="150" height ="50"></a>!-->
	    <p><strong><a href="./papers/Rangesh_T_ITS_2016.pdf">Long-term, Multi-Cue Tracking of Hands in Vehicles</a></strong><br>
	    A. Rangesh, <strong>E. Ohn-Bar</strong>, and M. Trivedi<br>
	    <em>IEEE Transactions on Intelligent Transportation Systems (<strong>T-ITS</strong>)</em>, 2016<font color="gray">  Impact factor: 5.74</font><br>
	    [<a href="./papers/Rangesh_T_ITS_2016.pdf">pdf</a> | <a href="http://cvrr.ucsd.edu/vivachallenge">data </a> | <a href="./papers/Rangesh_T_ITS_2016.txt">bibtex</a>]
    </div>

                <div class="publication">
		    <a href="./papers/Multires_Peds.pdf"><img width="150" height ="150" src="./images/multires.png" class="publogo"></a>
		    <p><strong><a href="./papers/Multires_Peds.pdf">Looking at Pedestrians at Different Scales: A Multiresolution Approach and Evaluations</a></strong><br>
		    R. N. Rajaram, <strong>E. Ohn-Bar</strong>, and M. Trivedi<br>
		    <em>IEEE Transactions on Intelligent Transportation Systems (<strong>T-ITS</strong>)</em>, 2016<font color="gray">  Impact factor: 5.74</font><br>
		    [<a href="./papers/Multires_Peds.pdf">pdf</a> | <a href="./papers/Multires_Peds.txt">bibtex</a>]
    </div>

        <div class="publication">
			<a href="./papers/imp_icpr.pdf"><img src="./images/imp2a.png" class="publogo" width="150" height="110"></a>
		    <p><strong><a href="./papers/imp_icpr.pdf">What Makes an On-road Object Important? <font color="red">(oral presentation)</font></a></strong><br>
			<strong>E. Ohn-Bar</strong> and M. Trivedi<br>
			<em>IEEE International Conference on Pattern Recognition (<strong>ICPR</strong>)</em>, 2016<font color="gray">  Acceptance rate: 14%</font><br>
			<b><font color="red">Best student paper award finalist</font></b><br>
			[<a href="./papers/imp_icpr.pdf">pdf</a> | <a href="https://github.com/eshed1/Object_Importance">data and code</a> | <a href="object_importance.html">project</a> | <a href="./papers/imp_icpr.txt">bibtex</a>]
    </div>


    <br>
        <div class="publication">
			<a href="./papers/boostornot.pdf"><img src="./images/boostn1.png" class="publogo" width="150" height="110"></a>
		    <p><strong><a href="./papers/boostornot.pdf">To Boost or Not to Boost? On the Limits of Boosted Trees for Object Detection <font color="red">(oral presentation)</font></a></strong><br>
			<strong>E. Ohn-Bar</strong> and M. Trivedi<br>
			<em>IEEE International Conference on Pattern Recognition (<strong>ICPR</strong>)</em>, 2016<font color="gray">  Acceptance rate: 14%</font><br>
			<b><font color="red">Best student paper award finalist</font></b><br>
			[<a href="./papers/boostornot.pdf">pdf</a> |  <a href="./code/BoostICPR.zip">Models, Results on Caltech/FDDB/WIDER and training code</a> | <a href="./papers/boostornot.txt">bibtex</a>]
    </div>

    <!--
<p style="margin:-12px 0px 0px 0px;"></p>
    <ul class="list-group">
      <li class="list-group-item" style="padding:0 0 0.2% 1.0%;">
<div class="media">
<div class="pull-left text-center" style="padding:11px 3.4% 0 0;">
   <a href="papers/refinenet_TIV.pdf"><img width="300" height = "220" src="images/refinenet.png"></a>
</div>
   <br>
   <h4 style="font-size:18px; line-height:120%">RefineNet: Iterative Refinement for Accurate Object Localization</h4>
   <p style="margin:-8px 0px 0px 0px;"></p>
   <p style="font-size:18px" style="padding:0px 0px 0px 0px;">R. N. Rajaram, <strong>E. Ohn-Bar</strong> and M. Trivedi</p>
   <p style="margin:-10px 0px 0px 0px;"></p><p style="font-size:18px" style="padding:0px 0px 0px 0px;">In <em>Submitted to IEEE Transactions on Intelligent Vehicles</em> (<strong>T-IV</strong>), 2016</p>
   <p style="margin:-8px 0px 0px 0px;"></p>[<a href="papers/refinenet_TIV.pdf">pdf</a>]
</div>
      </li>
    </ul>
<p style="margin:-8px 0px 0px 0px;"></p>
!-->

<br>
  <div class="publication">
			<a href="./papers/refineNetITSC.pdf"><img src="./images/refinenet.png" class="publogo" width="150" height="110"></a>
		    <p><strong><a href="./papers/refineNetITSC.pdf">RefineNet: Iterative Refinement for Accurate Object Localization</a></strong><br>
			R. N. Rajaram, <strong>E. Ohn-Bar</strong>, and M. Trivedi<br>
			<em>IEEE Intelligent Transportation Systems Conference (<strong>ITSC</strong>)</em>, 2016<br>
			[<a href="./papers/refineNetITSC.pdf">pdf</a> | <a href="./papers/refineNetITSC.txt">bibtex</a>]
    </div>
  <div class="publication">
			<a href="./papers/surrRNN.pdf"><img src="./images/sur3.png" class="publogo" width="150" height="110"></a>
		    <p><strong><a href="./papers/surrRNN.pdf">Surround Vehicles Trajectory Analysis with Recurrent Neural Networks</a></strong><br>
			A. Khosroshahi, <strong>E. Ohn-Bar</strong>, and M. Trivedi<br>
			<em>IEEE Intelligent Transportation Systems Conference (<strong>ITSC</strong>)</em>, 2016<br>
			[<a href="./papers/surrRNN.pdf">pdf</a> | <a href="./papers/surrRNN.txt">bibtex</a>]
    </div>
<br>
      <div class="publication">
				<a href="./papers/pedsphones.pdf"><img src="./images/pedsactivity.png" class="publogo" width="150" height="110"></a>
			    <p><strong><a href="./papers/pedsphones.pdf">Pedestrians and their Phones - Detecting Phone-based Activities of Pedestrians for Autonomous Vehicles</a></strong><br>
				A. Rangesh, <strong>E. Ohn-Bar</strong>, K. Yuen, and M. Trivedi<br>
				<em>IEEE Intelligent Transportation Systems Conference (<strong>ITSC</strong>)</em>, 2016<br>
				[<a href="./papers/pedsphones.pdf">pdf</a> | <a href="./papers/pedsphones.txt">bibtex</a>]
	    </div>

      <div class="publication">
				<a href="./papers/0575.pdf"><img src="./images/pano.png" class="publogo" width="150" height="110"></a>
			    <p><strong><a href="./papers/0575.pdf">Multi-Perspective Vehicle Detection and Tracking: Challenges, Dataset, and Metrics</a></strong><br>
				J. V. Dueholm, M. S. Kristoffersen, R. Satzoda, <strong>E. Ohn-Bar</strong>, T. B. Moeslund, and M. Trivedi<br>
				<em>IEEE Intelligent Transportation Systems Conference (<strong>ITSC</strong>)</em>, 2016<br>
				[<a href="./papers/0575.pdf">pdf</a> | <a href="./papers/pano.txt">bibtex</a>]
	    </div>

          <div class="publication">
			<a href="./papers/mss_icpr.pdf"><img src="./images/mss.png" class="publogo" width="150" height="110"></a>
		    <p><strong><a href="./papers/mss_icpr.pdf">Detection and Localization with Multi-scale Models <font color="red">(oral presentation)</font></a></strong><br>
			<strong>E. Ohn-Bar</strong> and M. Trivedi<br>
			<em>IEEE International Conference on Pattern Recognition (<strong>ICPR</strong>)</em>, 2016<font color="gray">  Acceptance rate: 14%</font><br>
			[<a href="./papers/mss_icpr.pdf">pdf</a> | <a href="./papers/mss_icpr.txt">bibtex</a>]
    </div>

<a name="2015">2015</a> <hr style="height:3px;border:none;color:#808080;background-color:#808080;margin-top: -12px;margin-left: 50px;top: 50%;width: 100%;content: "";display: inline-block;"/>

<!--
    <div class="publication">
	    <a href="./papers/outofbox.pdf"><img src="./images/outofbox.png" class="publogo" width="150" height ="110"></a>
	    <p><strong><a href="./papers/outofbox.pdf">Looking outside of the Box: Object Detection and Localization with Multi-scale Patterns</a></strong><br>
	    <strong>E. Ohn-Bar</strong> and M. Trivedi<br>
	    <em>arXiv</em>, 2015<br>
	    [<a href="./papers/outofbox.pdf">pdf</a> | <a href="./papers/outofbox.txt">bibtex</a>]
    </div>
    -->
	
		<div class="publication">
	    <a href="./papers/CVIUpredict.pdf"><img src="./images/cviu.jpg" class="publogo" width="150"></a>
	    <p><strong><a href="./papers/CVIUpredict.pdf">On Surveillance for Safety Critical Events: In-Vehicle Video Networks for Predictive Driver Assistance Systems</a></strong><br>
	    <strong>E. Ohn-Bar</strong>, A. Tawari, S. Martin, and M. Trivedi<br>
	    <em>Computer Vision and Image Understanding (<strong>CVIU</strong>)</em>, 2015<font color="gray">  Impact factor: 2.77</font><br>
	    [<a href="./papers/CVIUpredict.pdf">pdf</a> | <a href="./papers/cviu.txt">bibtex</a>]
    </div>

	<div class="publication">
	    <a href="./papers/OhnBar_TITS15_wsupplement.pdf"><img height="350" width="150" src="./images/subcat2_long.png" class="publogo"></a>
	    <p><strong><a href="./papers/OhnBar_TITS15_wsupplement.pdf">Learning to Detect Vehicles by Clustering Appearance Patterns</a></strong><br>
	    <strong>E. Ohn-Bar</strong> and M. Trivedi<br>
	    <em>IEEE Transactions on Intelligent Transportation Systems (<strong>T-ITS</strong>)</em>, 2015<font color="gray">  Impact factor: 5.74</font><br>
	    [<a href="./papers/OhnBar_TITS15_wsupplement.pdf">pdf (with supplementary)</a> | <a href="subcat/index.html"><font color="red">code</font></a> | <a href="./papers/OhnBar_TITS15_wsupplement.txt">bibtex</a>]

    </div>

	<div class="publication">
	    <a href="./papers/Das_ITSC2015.pdf"><img src="./images/viva.png" class="publogo" width="150" height = "105"></a>
	    <p><strong><a href="./papers/Das_ITSC2015.pdf">On Performance Evaluation of Driver Hand Detection Algorithms: Challenges, Dataset, and Metrics</a></strong><br>
	    N. Das, <strong>E. Ohn-Bar</strong>, and M. Trivedi<br>
	    <em>IEEE Conference on Intelligent Transportation Systems (<strong>ITSC</strong>)</em>, 2015<br>
	    [<a href="./papers/Das_ITSC2015.pdf">pdf</a> | <a href="http://cvrr.ucsd.edu/vivachallenge/index.php/hands/hand-detection/">data</a> | <a href="./papers/Das_ITSC15.txt">bibtex</a>]
    </div>

	<div class="publication">
	    <a href="./papers/Nattoji_ITSC2015.pdf"><img src="./images/peds_notxt.png" class="publogo" width="150" height = "100"></a>
	    <p><strong><a href="./papers/Nattoji_ITSC2015.pdf">An Exploration of Why and When Pedestrian Detection Fails</a></strong><br>
	    R. N. Rajaram, <strong>E. Ohn-Bar</strong>, and M. Trivedi<br>
	    <em>IEEE Conference on Intelligent Transportation Systems (<strong>ITSC</strong>)</em>, 2015<br>
	    [<a href="./papers/Nattoji_ITSC2015.pdf">pdf</a> | <a href="./papers/Nattoji_ITSC15.txt">bibtex</a>]
    </div>
<br>
	<div class="publication">
	    <a href="./papers/OhnBar_IV15_hands.pdf"><img src="./images/handscomp_long.png" class="publogo" width="150" height = "300"></a>
	    <p><strong><a href="./papers/OhnBar_IV15_hands.pdf">A Comparative Study of Color and Depth Features for Hand Gesture Recognition in Naturalistic Driving Settings</a></strong><br>
	    <strong>E. Ohn-Bar</strong> and M. Trivedi<br>
	    <em>IEEE Intelligent Vehicles Symposium (<strong>IV</strong>)</em>, 2015<br>
	    [<a href="./papers/OhnBar_IV15_hands.pdf">pdf</a> | <a href="./papers/OhnBar_IV15_hands.txt">bibtex</a>]
    </div>
    <br>

	<div class="publication">
	    <a href="./papers/OhnBar_IV15_peds.pdf"><img src="./images/subcatpeds.png" class="publogo" width="150" height = "90"></a>
	    <p><strong><a href="./papers/OhnBar_IV15_peds.pdf">Can Appearance Patterns Improve Pedestrian Detection?</a></strong><br>
	    <strong>E. Ohn-Bar</strong> and M. Trivedi<br>
	    <em>IEEE Intelligent Vehicles Symposium (<strong>IV</strong>)</em>, 2015<br>
	    [<a href="./papers/OhnBar_IV15_peds.pdf">pdf</a> | <a href="./papers/OhnBar_IV15_peds.txt">bibtex</a>]
    </div>

<a name="2014">2014</a> <hr style="height:3px;border:none;color:#808080;background-color:#808080;margin-top: -12px;margin-left: 50px;top: 50%;width: 100%;content: "";display: inline-block;"/>

	<div class="publication">
		    <a href="./papers/OhnBar_IEEETITS2014.pdf"><img src="./images/itshands_l.png" class="publogo" width="150"></a>
		    <p><strong><a href="./papers/OhnBar_IEEETITS2014.pdf">Hand Gesture Recognition in Real-Time for Automotive Interfaces: A Multimodal Vision-based Approach and Evaluations</a></strong><br>
		    <strong>E. Ohn-Bar</strong> and M. Trivedi<br>
		    <em>IEEE Transactions on Intelligent Transportation Systems (<strong>T-ITS</strong>)</em>, 2014<font color="gray">  Impact factor: 5.74</font><br>
		    [<a href="./papers/OhnBar_IEEETITS2014.pdf">pdf</a> | <a href="./papers/OhnBar_IEEETITS2014.txt">bibtex</a>]
    </div>
<br>
    <div class="publication">
			<a href="./papers/beyondHands.pdf"><img src="./images/beyond.png" class="publogo" width="150" height="110"></a>
		    <p><strong><a href="./papers/beyondHands.pdf">Beyond Just Keeping Hands on the Wheel: Towards Visual Interpretation of Driver Hand Motion Patterns</a></strong><br>
			<strong>E. Ohn-Bar</strong> and M. Trivedi<br>
			<em>IEEE Conference on Intelligent Transportation Systems (<strong>ITSC</strong>)</em>, 2014<br>
			[<a href="./papers/beyondHands.pdf">pdf</a> | <a href="./papers/hands_ITSC14.txt">bibtex</a>]
    </div>
<br>
	<div class="publication">
			<a href="./papers/vow.pdf"><img src="./images/vow_1l.png" class="publogo" width="150" height = "110"></a>
		    <p><strong><a href="./papers/vow.pdf">Vision on Wheels: Looking at Driver, Vehicle, and Surround for On-Road Maneuver Analysis <font color="red">(oral presentation)</font></a></strong><br>
			<strong>E. Ohn-Bar</strong>, A. Tawari, S. Martin, and M. Trivedi<br>
			<em>Mobile Vision Workshop, IEEE Conf. Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2014<br>
			[<a href="./papers/vow.pdf">pdf</a> | <a href="./papers/vow.txt">bibtex</a>]
    </div>

    <div class="publication">
			<a href="./papers/headhandeye.pdf"><img src="./images/conceptHeadHandl.png" class="publogo" width="150" height="110"></a>
		    <p><strong><a href="./papers/headhandeye.pdf">Head, Eye, and Hand Patterns for Driver Activity Recognition <font color="red">(oral presentation)</font></a></strong><br>
			<strong>E. Ohn-Bar</strong>, S. Martin, A. Tawari, and M. Trivedi<br>
			<em>IEEE International Conference on Pattern Recognition (<strong>ICPR</strong>)</em>, 2014<font color="gray">  Acceptance rate: 14%</font><br>
			<b><font color="red">Best Industry Related Paper Award Runner Up</font></b><br>
			[<a href="./papers/headhandeye.pdf">pdf</a> | <a href="./papers/headhandeye.txt">bibtex</a>]
    </div>
<br>
    <div class="publication">
			<a href="./papers/subcat.pdf"><img src="./images/o3l.png" class="publogo" width="150" height="110"></a>
		    <p><strong><a href="./papers/subcat.pdf">Fast and Robust Object Detection Using Visual Subcategories <font color="red">(oral presentation)</font></a></strong><br>
			<strong>E. Ohn-Bar</strong> and M. Trivedi<br>
			<em>Mobile Vision Workshop, IEEE Conf. Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2014<br>
			[<a href="./papers/subcat.pdf">pdf</a> | <a href="subcat/index.html"><font color="red">code</font></a> | <a href="./papers/subcat.txt">bibtex</a>]
    </div>

    <div class="publication">
			<a href="./papers/holistic.pdf"><img src="./images/holistic.png" class="publogo" width="150" height="110"></a>
		    <p><strong><a href="./papers/holistic.pdf">Predicting Driver Maneuvers by Learning Holistic Features</a></strong><br>
			<strong>E. Ohn-Bar</strong>, A. Tawari, S. Martin, and M. Trivedi<br>
			<em>IEEE Intelligent Vehicles Symposium (<strong>IV</strong>)</em>, 2014<br>
			[<a href="./papers/holistic.pdf">pdf</a> | <a href="./papers/holistic.txt">bibtex</a>]
    </div>

    <div class="publication">
			<a href="./papers/goflow.pdf"><img src="./images/o4_1.png" class="publogo" width="150" height="110"></a>
		    <p><strong><a href="./papers/goflow.pdf">Go with the Flow: Improving Multi-View Vehicle Detection with Motion Cues</a></strong><br>
			A. Ramirez, <strong>E. Ohn-Bar</strong>, and M. Trivedi<br>
			<em>IEEE International Conference on Pattern Recognition (<strong>ICPR</strong>)</em>, 2014<br>
			[<a href="./papers/goflow.pdf">pdf</a> | <a href="./papers/goflow.txt">bibtex</a>]
    </div>


<!--	<li><p align="left"><strong>Integrating Motion and Appearance for Overtaking Vehicle Detection</strong><br/>
	A. Ramirez, <strong><strong>E. Ohn-Bar</strong></strong>, and M. Trivedi, <em>IEEE Intelligent Vehicles Symposium</em>, 2014. [<a href="./papers/vehiclemotion.pdf">pdf</a> | <a href="./papers/vehiclemotion.txt">bibtex</a>]</p></li>
-->





<a name="2013">2013</a> <hr style="height:3px;border:none;color:#808080;background-color:#808080;margin-top: -12px;margin-left: 50px;top: 50%;width: 100%;content: "";display: inline-block;"/>
<!--
<li><p align="left"><strong>Driver Hand Activity Analysis in Naturalistic Driving Studies: Issues, Algorithms and Experimental Studies</strong><br/>
<strong><strong>E. Ohn-Bar</strong></strong>, S. Martin, and M. Trivedi, <em>Journal of Electronic Imaging: special section on Video Surveillance and Transportation Imaging Applications</em>, vol. 22, No. 4, 2013.[<a href="./papers/hand_JEI13.pdf">pdf</a> | <a href="./papers/handJEI13.txt">bibtex</a> ]   </p></li>
-->
    <div class="publication">
			<a href="./papers/hand_JEI13.pdf"><img src="./images/jei.png" class="publogo" width="150" height = "120"></a>
		    <p><strong><a href="./papers/hand_JEI13.pdf">Driver Hand Activity Analysis in Naturalistic Driving Studies: Issues, Algorithms and Experimental Studies</a></strong><br>
			<strong>E. Ohn-Bar</strong>, S. Martin, and M. Trivedi<br>
			<em>Journal of Electronic Imaging: Special Section on Video Surveillance and Transportation Imaging Applications (<strong>JEI</strong>)</em>, 2013<br>
			[<a href="./papers/hand_JEI13.pdf">pdf</a> | <a href="./papers/handJEI13.txt">bibtex</a>]
    </div>

    <div class="publication">
			<a href="./papers/OhnBarHAU3D13.pdf"><img src="./images/jas2l.png" class="publogo" width="150" height = "50"></a>
		    <p><strong><a href="./papers/OhnBarHAU3D13.pdf">Joint Angles Similarities and HOG2 for Action Recognition <font color="red">(oral presentation)</font></a></strong><br>
			<strong>E. Ohn-Bar</strong> and M. Trivedi<br>
			<em>Human Activity Understanding from 3D Data Workshop, IEEE Conf. Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2013<br>
			[<a href="./papers/OhnBarHAU3D13.pdf">pdf</a> | <a href="./code/HOG2code.zip"><font color="red">code</font></a> |  <a href="./papers/HAU3D_slides.pdf">slides</a> | <a href="./papers/OhnBarHAU3D13.txt">bibtex</a>]
    </div>

    <div class="publication">
			<a href="./papers/OhnBarAMFG13.pdf"><img src="./images/kinect2.png" class="publogo" width="150" height = "120"></a>
		    <p><strong><a href="./papers/OhnBarAMFG13.pdf">The Power is in Your Hands: 3D Analysis of Hand Gestures in Naturalistic Video <font color="red">(oral presentation, <b><font color="red">Best Paper Award</font></b>)</font></a></strong><br>
			<strong>E. Ohn-Bar</strong> and M. Trivedi<br>
			<em>Analysis and Modeling of Faces and Gestures Workshop, IEEE Conf. Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2013<font color="gray">  Acceptance rate: 30%</font><br>
			[<a href="./papers/OhnBarAMFG13.pdf">pdf</a> | <a href="http://cvrr.ucsd.edu/LISA/hand.html">dataset </font></a> |  <a href="./papers/OhnBarAMFG13.pdf">slides</a> | <a href="./papers/OhnBarAMFG13.txt">bibtex</a>]
    </div>
<br>
    <div class="publication">
			<a href="./papers/OhnbarSivaramanTrivediIV13.pdf"><img src="./images/overt.png" class="publogo" width="150" height="110"></a>
		    <p><strong><a href="./papers/OhnbarSivaramanTrivediIV13.pdf">Partially Occluded Vehicle Recognition and Tracking in 3D</a></strong><br>
			<strong>E. Ohn-Bar</strong>, S. Sivaraman, and M. Trivedi<br>
			<em>IEEE Intelligent Vehicles Symposium (<strong>IV</strong>)</em>, 2013<br>
			[<a href="./papers/OhnbarSivaramanTrivediIV13.pdf">pdf</a> | <a href="papers/iv2013_overt_poster.pdf">poster</a> | <a href="./papers/OhnBar_IV13_overt.txt">bibtex</a>]
    </div>

<li><p align="left"><strong>In-Vehicle Hand Activity Recognition Using Integration of Regions <font color="red">(oral presentation)</font></strong><br/>
  <strong><strong>E. Ohn-Bar</strong></strong> and M. Trivedi, <em>IEEE Intelligent Vehicles Symposium (<strong>IV</strong>)</em>, 2013. [<a href="./papers/ohnbar_IV13.pdf">pdf</a> | <a href="./papers/ohnbar_IV13.txt">bibtex</a>]</p></li>

<li><p align="left"><strong>Hand Gesture-based Visual User Interface for Infotainment <font color="red">(oral presentation)</font></strong><br/>
<strong><strong>E. Ohn-Bar</strong></strong>, C. Tran, M. Trivedi, <em>Automotive User Interfaces and Interactive Vehicular Applications (<strong>AUTO-UI</strong>)</em>, 2012. [<a href="./papers/OhnBar_AutoUI12.pdf">pdf</a> | <a href="./papers/OhnBar_AutoUI12.txt">bibtex</a>]</p></li>


</div>



<div class="container">
    <a name="ProfessionalActivity"></a>
    <h2>Professional Activity</h2>
	<br>
	Associate Editor
	<li>IEEE International Conference on Robotics and Automation
	<li>IEEE Intelligent Vehicles Symposium
	<br>
	<br>
	Program Committee/Workshop Organization
	<li>Workshop on Human Behavior Understanding at ICCV 2019, FG 2018
    <li>Workshop on Observing and Understanding Hands at CVPR, ICCV, ECCV (2015-2019)
    <li>Workshop on Automatic Traffic Surveillance at CVPR
	<br>
	<br>
	Reviewer
	<li>Computer Vision: CVPR, SIGGRAPH, PAMI, CVIU, CVPRW-ATS, CVPRW-HANDS, IMAVIS, T-SMC, T-CSVT, JEI 
	<li>Accessibility: ASSETS, T-ACCESS
	<li>Intelligent Vehicles: IV, ITSC, T-ITS, T-VT
	<li>Robotics and Systems: HRI, IROS, T-HMS, T-IE, T-II
	<br>
</div>

<div class="container">

</div>
</body>


<!--My research agenda involves two main components: 1) Development of new technologies for autonomous robots and driving, capable of operating in real-world environments, and 2) Human-centric robots, including human observing (e.g. driver or pedestrian behavior studies) and human-like (e.g. contextual, attentive, multi-modal). Addressing these objectives requires a multi-disciplinary effort for establishing novel benchmarks and metrics, as well as designing novel learning algorithms for semantic video understanding, situational awareness, human state modeling, information fusion, predictive systems, and decision making. Specifically, I wish to design machine learning algorithm which can robustly predict what is going to happen in a scene in the near future given multiple cameras and sensors.
-->

</html>



